{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usandor Tensorflow version 2.13.1\n",
      "Usando GPU: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 10:16:33.547023: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 10:16:33.547158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 10:16:33.547212: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 10:16:33.547308: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 10:16:33.547361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 10:16:33.547410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 3493 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2023-11-20 10:16:33.547499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 10:16:33.547557: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 10:16:33.547620: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 10:16:33.547682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 10:16:33.547744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-20 10:16:33.547789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /device:GPU:0 with 3493 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Usandor Tensorflow version \" + tf.__version__)\n",
    "\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "  print('Usando GPU: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "  print(\"Usando CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_LAYERS = [1,2]\n",
    "NUMBER_OF_NEURONS = [[25,25,25,25],[50,50,50,50],[100,100,100,100],[200,200,200,200], [1000,1000,1000,1000]]\n",
    "NUMBER_OF_STEPS = [1,2,3,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "import pandas as pd\n",
    "from empresa4.datasets import get_dataset, nombres_datasets\n",
    "from keras.callbacks import EarlyStopping\n",
    "from datetime import datetime\n",
    "from empresa4.core import calculate_error_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split a single time series into overlapping sequences\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps\n",
    "        if end_ix > len(sequences):\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix - 1, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>product_category</th>\n",
       "      <th>cat2</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>479.0</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201701</td>\n",
       "      <td>20002</td>\n",
       "      <td>391.0</td>\n",
       "      <td>555.18654</td>\n",
       "      <td>550.15707</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201701</td>\n",
       "      <td>20003</td>\n",
       "      <td>438.0</td>\n",
       "      <td>1067.81543</td>\n",
       "      <td>1063.45835</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>475.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701</td>\n",
       "      <td>20004</td>\n",
       "      <td>339.0</td>\n",
       "      <td>569.37394</td>\n",
       "      <td>555.91614</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201701</td>\n",
       "      <td>20005</td>\n",
       "      <td>249.0</td>\n",
       "      <td>494.60084</td>\n",
       "      <td>494.27011</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33691</th>\n",
       "      <td>201902</td>\n",
       "      <td>21235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>PC</td>\n",
       "      <td>PIEL1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33692</th>\n",
       "      <td>201902</td>\n",
       "      <td>21236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>PC</td>\n",
       "      <td>PIEL1</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33693</th>\n",
       "      <td>201902</td>\n",
       "      <td>21115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33694</th>\n",
       "      <td>201902</td>\n",
       "      <td>20734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33695</th>\n",
       "      <td>201902</td>\n",
       "      <td>21243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33696 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       periodo  product_id  cust_request_qty  cust_request_tn          tn  \\\n",
       "0       201701       20001             479.0        937.72717   934.77222   \n",
       "1       201701       20002             391.0        555.18654   550.15707   \n",
       "2       201701       20003             438.0       1067.81543  1063.45835   \n",
       "3       201701       20004             339.0        569.37394   555.91614   \n",
       "4       201701       20005             249.0        494.60084   494.27011   \n",
       "...        ...         ...               ...              ...         ...   \n",
       "33691   201902       21235               0.0          0.00000     0.00000   \n",
       "33692   201902       21236               0.0          0.00000     0.00000   \n",
       "33693   201902       21115               0.0          0.00000     0.00000   \n",
       "33694   201902       20734               0.0          0.00000     0.00000   \n",
       "33695   201902       21243               0.0          0.00000     0.00000   \n",
       "\n",
       "      product_category         cat2  sku_size  plan_precios_cuidados  \n",
       "0                   HC  ROPA LAVADO    3000.0                      0  \n",
       "1                   HC  ROPA LAVADO    3000.0                      0  \n",
       "2                FOODS     ADEREZOS     475.0                      0  \n",
       "3                FOODS     ADEREZOS     240.0                      0  \n",
       "4                FOODS     ADEREZOS     120.0                      0  \n",
       "...                ...          ...       ...                    ...  \n",
       "33691               PC        PIEL1     200.0                      0  \n",
       "33692               PC        PIEL1     400.0                      0  \n",
       "33693               PC         DEOS      89.0                      0  \n",
       "33694               PC      CABELLO     400.0                      0  \n",
       "33695               PC         DEOS      70.0                      0  \n",
       "\n",
       "[33696 rows x 9 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "df = get_dataset(\"02_productos_todos_anti_leak\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>201701_norm</th>\n",
       "      <th>201702_norm</th>\n",
       "      <th>201703_norm</th>\n",
       "      <th>201704_norm</th>\n",
       "      <th>201705_norm</th>\n",
       "      <th>201706_norm</th>\n",
       "      <th>201707_norm</th>\n",
       "      <th>201708_norm</th>\n",
       "      <th>201709_norm</th>\n",
       "      <th>...</th>\n",
       "      <th>201806_norm</th>\n",
       "      <th>201807_norm</th>\n",
       "      <th>201808_norm</th>\n",
       "      <th>201809_norm</th>\n",
       "      <th>201810_norm</th>\n",
       "      <th>201811_norm</th>\n",
       "      <th>201812_norm</th>\n",
       "      <th>201901_norm</th>\n",
       "      <th>201902_norm</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>0.091342</td>\n",
       "      <td>0.347663</td>\n",
       "      <td>0.567846</td>\n",
       "      <td>0.466153</td>\n",
       "      <td>0.654484</td>\n",
       "      <td>0.662267</td>\n",
       "      <td>0.449035</td>\n",
       "      <td>0.552176</td>\n",
       "      <td>0.573766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.501371</td>\n",
       "      <td>0.640632</td>\n",
       "      <td>0.784656</td>\n",
       "      <td>0.626804</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789908</td>\n",
       "      <td>0.647724</td>\n",
       "      <td>0.555827</td>\n",
       "      <td>0.548559</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>0.286313</td>\n",
       "      <td>0.472443</td>\n",
       "      <td>0.295634</td>\n",
       "      <td>0.477368</td>\n",
       "      <td>0.547960</td>\n",
       "      <td>0.478475</td>\n",
       "      <td>0.350738</td>\n",
       "      <td>0.602969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.585130</td>\n",
       "      <td>0.553193</td>\n",
       "      <td>0.657610</td>\n",
       "      <td>0.540080</td>\n",
       "      <td>0.780210</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.571334</td>\n",
       "      <td>0.716985</td>\n",
       "      <td>0.590329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>0.375239</td>\n",
       "      <td>0.383889</td>\n",
       "      <td>0.468175</td>\n",
       "      <td>0.268330</td>\n",
       "      <td>0.316705</td>\n",
       "      <td>0.379824</td>\n",
       "      <td>0.400778</td>\n",
       "      <td>0.441167</td>\n",
       "      <td>0.748375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337259</td>\n",
       "      <td>0.334958</td>\n",
       "      <td>0.488019</td>\n",
       "      <td>0.465740</td>\n",
       "      <td>0.670507</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.392968</td>\n",
       "      <td>0.492512</td>\n",
       "      <td>0.387094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>0.164645</td>\n",
       "      <td>0.400644</td>\n",
       "      <td>0.386223</td>\n",
       "      <td>0.403683</td>\n",
       "      <td>0.428377</td>\n",
       "      <td>0.465553</td>\n",
       "      <td>0.449286</td>\n",
       "      <td>0.822024</td>\n",
       "      <td>0.993244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353047</td>\n",
       "      <td>0.515169</td>\n",
       "      <td>0.738344</td>\n",
       "      <td>0.748157</td>\n",
       "      <td>0.638388</td>\n",
       "      <td>0.632612</td>\n",
       "      <td>0.461655</td>\n",
       "      <td>0.403118</td>\n",
       "      <td>0.348204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>0.179476</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>0.451804</td>\n",
       "      <td>0.530902</td>\n",
       "      <td>0.413083</td>\n",
       "      <td>0.423504</td>\n",
       "      <td>0.501455</td>\n",
       "      <td>0.855840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.438761</td>\n",
       "      <td>0.402467</td>\n",
       "      <td>0.701053</td>\n",
       "      <td>0.610395</td>\n",
       "      <td>0.716162</td>\n",
       "      <td>0.375956</td>\n",
       "      <td>0.298511</td>\n",
       "      <td>0.291258</td>\n",
       "      <td>0.328378</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>21295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>21296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>21297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>21298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>21299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1296 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id  201701_norm  201702_norm  201703_norm  201704_norm  \\\n",
       "0          20001     0.091342     0.347663     0.567846     0.466153   \n",
       "1          20002     0.035110     0.286313     0.472443     0.295634   \n",
       "2          20003     0.375239     0.383889     0.468175     0.268330   \n",
       "3          20004     0.164645     0.400644     0.386223     0.403683   \n",
       "4          20005     0.179476     0.441811     0.451804     0.530902   \n",
       "...          ...          ...          ...          ...          ...   \n",
       "1291       21295     1.000000     0.000000     0.000000     0.000000   \n",
       "1292       21296     0.000000     0.000000     0.000000     0.000000   \n",
       "1293       21297     1.000000     0.000000     0.000000     0.000000   \n",
       "1294       21298     0.000000     0.000000     0.000000     0.000000   \n",
       "1295       21299     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "      201705_norm  201706_norm  201707_norm  201708_norm  201709_norm  ...  \\\n",
       "0        0.654484     0.662267     0.449035     0.552176     0.573766  ...   \n",
       "1        0.477368     0.547960     0.478475     0.350738     0.602969  ...   \n",
       "2        0.316705     0.379824     0.400778     0.441167     0.748375  ...   \n",
       "3        0.428377     0.465553     0.449286     0.822024     0.993244  ...   \n",
       "4        0.413083     0.423504     0.501455     0.855840     1.000000  ...   \n",
       "...           ...          ...          ...          ...          ...  ...   \n",
       "1291     0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "1292     0.000000     0.000000     0.000000     1.000000     0.000000  ...   \n",
       "1293     0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "1294     0.000000     0.000000     0.000000     1.000000     0.000000  ...   \n",
       "1295     0.000000     0.000000     0.000000     1.000000     0.000000  ...   \n",
       "\n",
       "      201806_norm  201807_norm  201808_norm  201809_norm  201810_norm  \\\n",
       "0        0.501371     0.640632     0.784656     0.626804     1.000000   \n",
       "1        0.585130     0.553193     0.657610     0.540080     0.780210   \n",
       "2        0.337259     0.334958     0.488019     0.465740     0.670507   \n",
       "3        0.353047     0.515169     0.738344     0.748157     0.638388   \n",
       "4        0.438761     0.402467     0.701053     0.610395     0.716162   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "1291     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1292     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1293     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1294     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "1295     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "\n",
       "      201811_norm  201812_norm  201901_norm  201902_norm  cluster  \n",
       "0        0.789908     0.647724     0.555827     0.548559        0  \n",
       "1        1.000000     0.571334     0.716985     0.590329        0  \n",
       "2        0.616162     0.392968     0.492512     0.387094        0  \n",
       "3        0.632612     0.461655     0.403118     0.348204        0  \n",
       "4        0.375956     0.298511     0.291258     0.328378        0  \n",
       "...           ...          ...          ...          ...      ...  \n",
       "1291     0.000000     0.000000     0.000000     0.000000        3  \n",
       "1292     0.000000     0.000000     0.000000     0.000000        1  \n",
       "1293     0.000000     0.000000     0.000000     0.000000        3  \n",
       "1294     0.000000     0.000000     0.000000     0.000000        1  \n",
       "1295     0.000000     0.000000     0.000000     0.000000        1  \n",
       "\n",
       "[1296 rows x 28 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_df = pd.read_csv(\"product_ids_clusters.csv\")\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add column cluster from cluster_df to df\n",
    "df = df.merge(cluster_df[[\"product_id\", \"cluster\"]], on='product_id', how='left')\n",
    "df[\"cluster\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>product_category</th>\n",
       "      <th>cat2</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>479.0</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>201702</td>\n",
       "      <td>20001</td>\n",
       "      <td>432.0</td>\n",
       "      <td>833.72187</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>201703</td>\n",
       "      <td>20001</td>\n",
       "      <td>509.0</td>\n",
       "      <td>1330.74697</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>201704</td>\n",
       "      <td>20001</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1132.94430</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>201705</td>\n",
       "      <td>20001</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1550.68936</td>\n",
       "      <td>1502.20132</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>201706</td>\n",
       "      <td>20001</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1575.82891</td>\n",
       "      <td>1520.06539</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>201707</td>\n",
       "      <td>20001</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1086.47101</td>\n",
       "      <td>1030.67391</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>201708</td>\n",
       "      <td>20001</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1289.66869</td>\n",
       "      <td>1267.39462</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>201709</td>\n",
       "      <td>20001</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1356.96103</td>\n",
       "      <td>1316.94604</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>201710</td>\n",
       "      <td>20001</td>\n",
       "      <td>273.0</td>\n",
       "      <td>1441.60247</td>\n",
       "      <td>1439.75563</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>201711</td>\n",
       "      <td>20001</td>\n",
       "      <td>519.0</td>\n",
       "      <td>1586.94356</td>\n",
       "      <td>1580.47401</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>201712</td>\n",
       "      <td>20001</td>\n",
       "      <td>435.0</td>\n",
       "      <td>1098.83929</td>\n",
       "      <td>1049.38860</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9832</th>\n",
       "      <td>201801</td>\n",
       "      <td>20001</td>\n",
       "      <td>437.0</td>\n",
       "      <td>1256.01136</td>\n",
       "      <td>1169.07532</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>201802</td>\n",
       "      <td>20001</td>\n",
       "      <td>302.0</td>\n",
       "      <td>1150.37849</td>\n",
       "      <td>1043.76470</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11534</th>\n",
       "      <td>201803</td>\n",
       "      <td>20001</td>\n",
       "      <td>591.0</td>\n",
       "      <td>1902.79056</td>\n",
       "      <td>1856.83534</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12387</th>\n",
       "      <td>201804</td>\n",
       "      <td>20001</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1286.12277</td>\n",
       "      <td>1251.28462</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>201805</td>\n",
       "      <td>20001</td>\n",
       "      <td>456.0</td>\n",
       "      <td>1303.62129</td>\n",
       "      <td>1293.89788</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14105</th>\n",
       "      <td>201806</td>\n",
       "      <td>20001</td>\n",
       "      <td>497.0</td>\n",
       "      <td>1198.50145</td>\n",
       "      <td>1150.79169</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14956</th>\n",
       "      <td>201807</td>\n",
       "      <td>20001</td>\n",
       "      <td>458.0</td>\n",
       "      <td>1528.59380</td>\n",
       "      <td>1470.41009</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15802</th>\n",
       "      <td>201808</td>\n",
       "      <td>20001</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1859.88471</td>\n",
       "      <td>1800.96168</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16650</th>\n",
       "      <td>201809</td>\n",
       "      <td>20001</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1629.37910</td>\n",
       "      <td>1438.67455</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17525</th>\n",
       "      <td>201810</td>\n",
       "      <td>20001</td>\n",
       "      <td>417.0</td>\n",
       "      <td>2423.70881</td>\n",
       "      <td>2295.19832</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18422</th>\n",
       "      <td>201811</td>\n",
       "      <td>20001</td>\n",
       "      <td>447.0</td>\n",
       "      <td>1945.84961</td>\n",
       "      <td>1813.01511</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19320</th>\n",
       "      <td>201812</td>\n",
       "      <td>20001</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1562.28968</td>\n",
       "      <td>1486.68669</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20212</th>\n",
       "      <td>201901</td>\n",
       "      <td>20001</td>\n",
       "      <td>370.0</td>\n",
       "      <td>1371.76430</td>\n",
       "      <td>1275.77351</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21099</th>\n",
       "      <td>201902</td>\n",
       "      <td>20001</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1343.99435</td>\n",
       "      <td>1259.09363</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       periodo  product_id  cust_request_qty  cust_request_tn          tn  \\\n",
       "0       201701       20001             479.0        937.72717   934.77222   \n",
       "785     201702       20001             432.0        833.72187   798.01620   \n",
       "1566    201703       20001             509.0       1330.74697  1303.35771   \n",
       "2352    201704       20001             279.0       1132.94430  1069.96130   \n",
       "3136    201705       20001             701.0       1550.68936  1502.20132   \n",
       "3942    201706       20001             570.0       1575.82891  1520.06539   \n",
       "4765    201707       20001             381.0       1086.47101  1030.67391   \n",
       "5591    201708       20001             643.0       1289.66869  1267.39462   \n",
       "6438    201709       20001             381.0       1356.96103  1316.94604   \n",
       "7267    201710       20001             273.0       1441.60247  1439.75563   \n",
       "8116    201711       20001             519.0       1586.94356  1580.47401   \n",
       "8976    201712       20001             435.0       1098.83929  1049.38860   \n",
       "9832    201801       20001             437.0       1256.01136  1169.07532   \n",
       "10686   201802       20001             302.0       1150.37849  1043.76470   \n",
       "11534   201803       20001             591.0       1902.79056  1856.83534   \n",
       "12387   201804       20001             384.0       1286.12277  1251.28462   \n",
       "13241   201805       20001             456.0       1303.62129  1293.89788   \n",
       "14105   201806       20001             497.0       1198.50145  1150.79169   \n",
       "14956   201807       20001             458.0       1528.59380  1470.41009   \n",
       "15802   201808       20001             535.0       1859.88471  1800.96168   \n",
       "16650   201809       20001             401.0       1629.37910  1438.67455   \n",
       "17525   201810       20001             417.0       2423.70881  2295.19832   \n",
       "18422   201811       20001             447.0       1945.84961  1813.01511   \n",
       "19320   201812       20001             453.0       1562.28968  1486.68669   \n",
       "20212   201901       20001             370.0       1371.76430  1275.77351   \n",
       "21099   201902       20001             367.0       1343.99435  1259.09363   \n",
       "\n",
       "      product_category         cat2  sku_size  plan_precios_cuidados  cluster  \n",
       "0                   HC  ROPA LAVADO    3000.0                      0        0  \n",
       "785                 HC  ROPA LAVADO    3000.0                      0        0  \n",
       "1566                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "2352                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "3136                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "3942                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "4765                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "5591                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "6438                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "7267                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "8116                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "8976                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "9832                HC  ROPA LAVADO    3000.0                      0        0  \n",
       "10686               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "11534               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "12387               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "13241               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "14105               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "14956               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "15802               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "16650               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "17525               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "18422               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "19320               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "20212               HC  ROPA LAVADO    3000.0                      0        0  \n",
       "21099               HC  ROPA LAVADO    3000.0                      0        0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"product_id\"] == 20001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "equiv = {\n",
    "    201701: 201703,\n",
    "    201702: 201704,\n",
    "    201703: 201705,\n",
    "    201704: 201706,\n",
    "    201705: 201707,\n",
    "    201706: 201708,\n",
    "    201707: 201709,\n",
    "    201708: 201710,\n",
    "    201709: 201711,\n",
    "    201710: 201712,\n",
    "    201711: 201801,\n",
    "    201712: 201802,\n",
    "    201801: 201803,\n",
    "    201802: 201804,\n",
    "    201803: 201805,\n",
    "    201804: 201806,\n",
    "    201805: 201807,\n",
    "    201806: 201808,\n",
    "    201807: 201809,\n",
    "    201808: 201810,\n",
    "    201809: 201811,\n",
    "    201810: 201812,\n",
    "    201811: 201901,\n",
    "    201812: 201902,\n",
    "    201901: 201903,\n",
    "    201902: 201904,\n",
    "    201903: 201905,\n",
    "    201904: 201906,\n",
    "    201905: 201907,\n",
    "    201906: 201908,\n",
    "    201907: 201909,\n",
    "    201908: 201910,\n",
    "    201909: 201911,\n",
    "    201910: 201912,\n",
    "    201911: 202001,\n",
    "    201912: 202002,\n",
    "    202001: 202003,\n",
    "    202002: 202004,\n",
    "}\n",
    "target_df = get_dataset(\"02_productos_todos\")\n",
    "\n",
    "\n",
    "# Filter data up to 201902\n",
    "def lag_target_class(row):\n",
    "    # from the column \"periodo\" and \"product_id\" of this row, get the equivalen periodo in equiv and get the tn column from \"target\" df for this product_id and the equiv periodo\n",
    "    product_id = row[\"product_id\"]\n",
    "    periodo = row[\"periodo\"]\n",
    "    periodo_equiv = equiv.get(periodo)\n",
    "    if periodo_equiv is None:\n",
    "        return None\n",
    "    value = target_df[(target_df[\"product_id\"] == product_id) & (target_df[\"periodo\"] == periodo_equiv)][\"tn\"].values[0]\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>product_category</th>\n",
       "      <th>cat2</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cluster</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>479.0</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1303.35771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>201701</td>\n",
       "      <td>20002</td>\n",
       "      <td>391.0</td>\n",
       "      <td>555.18654</td>\n",
       "      <td>550.15707</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>834.73521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201701</td>\n",
       "      <td>20003</td>\n",
       "      <td>438.0</td>\n",
       "      <td>1067.81543</td>\n",
       "      <td>1063.45835</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>475.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>917.16548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201701</td>\n",
       "      <td>20004</td>\n",
       "      <td>339.0</td>\n",
       "      <td>569.37394</td>\n",
       "      <td>555.91614</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>489.91328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201701</td>\n",
       "      <td>20005</td>\n",
       "      <td>249.0</td>\n",
       "      <td>494.60084</td>\n",
       "      <td>494.27011</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>ADEREZOS</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>563.89955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33691</th>\n",
       "      <td>201902</td>\n",
       "      <td>21235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>PC</td>\n",
       "      <td>PIEL1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33692</th>\n",
       "      <td>201902</td>\n",
       "      <td>21236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>PC</td>\n",
       "      <td>PIEL1</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33693</th>\n",
       "      <td>201902</td>\n",
       "      <td>21115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33694</th>\n",
       "      <td>201902</td>\n",
       "      <td>20734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>PC</td>\n",
       "      <td>CABELLO</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33695</th>\n",
       "      <td>201902</td>\n",
       "      <td>21243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>PC</td>\n",
       "      <td>DEOS</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33696 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       periodo  product_id  cust_request_qty  cust_request_tn          tn  \\\n",
       "0       201701       20001             479.0        937.72717   934.77222   \n",
       "1       201701       20002             391.0        555.18654   550.15707   \n",
       "2       201701       20003             438.0       1067.81543  1063.45835   \n",
       "3       201701       20004             339.0        569.37394   555.91614   \n",
       "4       201701       20005             249.0        494.60084   494.27011   \n",
       "...        ...         ...               ...              ...         ...   \n",
       "33691   201902       21235               0.0          0.00000     0.00000   \n",
       "33692   201902       21236               0.0          0.00000     0.00000   \n",
       "33693   201902       21115               0.0          0.00000     0.00000   \n",
       "33694   201902       20734               0.0          0.00000     0.00000   \n",
       "33695   201902       21243               0.0          0.00000     0.00000   \n",
       "\n",
       "      product_category         cat2  sku_size  plan_precios_cuidados  cluster  \\\n",
       "0                   HC  ROPA LAVADO    3000.0                      0        0   \n",
       "1                   HC  ROPA LAVADO    3000.0                      0        0   \n",
       "2                FOODS     ADEREZOS     475.0                      0        0   \n",
       "3                FOODS     ADEREZOS     240.0                      0        0   \n",
       "4                FOODS     ADEREZOS     120.0                      0        0   \n",
       "...                ...          ...       ...                    ...      ...   \n",
       "33691               PC        PIEL1     200.0                      0        1   \n",
       "33692               PC        PIEL1     400.0                      0        1   \n",
       "33693               PC         DEOS      89.0                      0        1   \n",
       "33694               PC      CABELLO     400.0                      0        1   \n",
       "33695               PC         DEOS      70.0                      0        1   \n",
       "\n",
       "           target  \n",
       "0      1303.35771  \n",
       "1       834.73521  \n",
       "2       917.16548  \n",
       "3       489.91328  \n",
       "4       563.89955  \n",
       "...           ...  \n",
       "33691     0.00000  \n",
       "33692     0.00000  \n",
       "33693     0.00000  \n",
       "33694     0.00000  \n",
       "33695     0.00000  \n",
       "\n",
       "[33696 rows x 11 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"] = df.apply(lag_target_class, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periodo</th>\n",
       "      <th>product_id</th>\n",
       "      <th>cust_request_qty</th>\n",
       "      <th>cust_request_tn</th>\n",
       "      <th>tn</th>\n",
       "      <th>product_category</th>\n",
       "      <th>cat2</th>\n",
       "      <th>sku_size</th>\n",
       "      <th>plan_precios_cuidados</th>\n",
       "      <th>cluster</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201701</td>\n",
       "      <td>20001</td>\n",
       "      <td>479.0</td>\n",
       "      <td>937.72717</td>\n",
       "      <td>934.77222</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1303.35771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>201702</td>\n",
       "      <td>20001</td>\n",
       "      <td>432.0</td>\n",
       "      <td>833.72187</td>\n",
       "      <td>798.01620</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1069.96130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>201703</td>\n",
       "      <td>20001</td>\n",
       "      <td>509.0</td>\n",
       "      <td>1330.74697</td>\n",
       "      <td>1303.35771</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1502.20132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "      <td>201704</td>\n",
       "      <td>20001</td>\n",
       "      <td>279.0</td>\n",
       "      <td>1132.94430</td>\n",
       "      <td>1069.96130</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1520.06539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>201705</td>\n",
       "      <td>20001</td>\n",
       "      <td>701.0</td>\n",
       "      <td>1550.68936</td>\n",
       "      <td>1502.20132</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1030.67391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>201706</td>\n",
       "      <td>20001</td>\n",
       "      <td>570.0</td>\n",
       "      <td>1575.82891</td>\n",
       "      <td>1520.06539</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1267.39462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4765</th>\n",
       "      <td>201707</td>\n",
       "      <td>20001</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1086.47101</td>\n",
       "      <td>1030.67391</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1316.94604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>201708</td>\n",
       "      <td>20001</td>\n",
       "      <td>643.0</td>\n",
       "      <td>1289.66869</td>\n",
       "      <td>1267.39462</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1439.75563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6438</th>\n",
       "      <td>201709</td>\n",
       "      <td>20001</td>\n",
       "      <td>381.0</td>\n",
       "      <td>1356.96103</td>\n",
       "      <td>1316.94604</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1580.47401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7267</th>\n",
       "      <td>201710</td>\n",
       "      <td>20001</td>\n",
       "      <td>273.0</td>\n",
       "      <td>1441.60247</td>\n",
       "      <td>1439.75563</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1049.38860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8116</th>\n",
       "      <td>201711</td>\n",
       "      <td>20001</td>\n",
       "      <td>519.0</td>\n",
       "      <td>1586.94356</td>\n",
       "      <td>1580.47401</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1169.07532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>201712</td>\n",
       "      <td>20001</td>\n",
       "      <td>435.0</td>\n",
       "      <td>1098.83929</td>\n",
       "      <td>1049.38860</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1043.76470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9832</th>\n",
       "      <td>201801</td>\n",
       "      <td>20001</td>\n",
       "      <td>437.0</td>\n",
       "      <td>1256.01136</td>\n",
       "      <td>1169.07532</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1856.83534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>201802</td>\n",
       "      <td>20001</td>\n",
       "      <td>302.0</td>\n",
       "      <td>1150.37849</td>\n",
       "      <td>1043.76470</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1251.28462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11534</th>\n",
       "      <td>201803</td>\n",
       "      <td>20001</td>\n",
       "      <td>591.0</td>\n",
       "      <td>1902.79056</td>\n",
       "      <td>1856.83534</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1293.89788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12387</th>\n",
       "      <td>201804</td>\n",
       "      <td>20001</td>\n",
       "      <td>384.0</td>\n",
       "      <td>1286.12277</td>\n",
       "      <td>1251.28462</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1150.79169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13241</th>\n",
       "      <td>201805</td>\n",
       "      <td>20001</td>\n",
       "      <td>456.0</td>\n",
       "      <td>1303.62129</td>\n",
       "      <td>1293.89788</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1470.41009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14105</th>\n",
       "      <td>201806</td>\n",
       "      <td>20001</td>\n",
       "      <td>497.0</td>\n",
       "      <td>1198.50145</td>\n",
       "      <td>1150.79169</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1800.96168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14956</th>\n",
       "      <td>201807</td>\n",
       "      <td>20001</td>\n",
       "      <td>458.0</td>\n",
       "      <td>1528.59380</td>\n",
       "      <td>1470.41009</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1438.67455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15802</th>\n",
       "      <td>201808</td>\n",
       "      <td>20001</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1859.88471</td>\n",
       "      <td>1800.96168</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2295.19832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16650</th>\n",
       "      <td>201809</td>\n",
       "      <td>20001</td>\n",
       "      <td>401.0</td>\n",
       "      <td>1629.37910</td>\n",
       "      <td>1438.67455</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1813.01511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17525</th>\n",
       "      <td>201810</td>\n",
       "      <td>20001</td>\n",
       "      <td>417.0</td>\n",
       "      <td>2423.70881</td>\n",
       "      <td>2295.19832</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1486.68669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18422</th>\n",
       "      <td>201811</td>\n",
       "      <td>20001</td>\n",
       "      <td>447.0</td>\n",
       "      <td>1945.84961</td>\n",
       "      <td>1813.01511</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1275.77351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19320</th>\n",
       "      <td>201812</td>\n",
       "      <td>20001</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1562.28968</td>\n",
       "      <td>1486.68669</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1259.09363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20212</th>\n",
       "      <td>201901</td>\n",
       "      <td>20001</td>\n",
       "      <td>370.0</td>\n",
       "      <td>1371.76430</td>\n",
       "      <td>1275.77351</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1470.65653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21099</th>\n",
       "      <td>201902</td>\n",
       "      <td>20001</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1343.99435</td>\n",
       "      <td>1259.09363</td>\n",
       "      <td>HC</td>\n",
       "      <td>ROPA LAVADO</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1647.63848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       periodo  product_id  cust_request_qty  cust_request_tn          tn  \\\n",
       "0       201701       20001             479.0        937.72717   934.77222   \n",
       "785     201702       20001             432.0        833.72187   798.01620   \n",
       "1566    201703       20001             509.0       1330.74697  1303.35771   \n",
       "2352    201704       20001             279.0       1132.94430  1069.96130   \n",
       "3136    201705       20001             701.0       1550.68936  1502.20132   \n",
       "3942    201706       20001             570.0       1575.82891  1520.06539   \n",
       "4765    201707       20001             381.0       1086.47101  1030.67391   \n",
       "5591    201708       20001             643.0       1289.66869  1267.39462   \n",
       "6438    201709       20001             381.0       1356.96103  1316.94604   \n",
       "7267    201710       20001             273.0       1441.60247  1439.75563   \n",
       "8116    201711       20001             519.0       1586.94356  1580.47401   \n",
       "8976    201712       20001             435.0       1098.83929  1049.38860   \n",
       "9832    201801       20001             437.0       1256.01136  1169.07532   \n",
       "10686   201802       20001             302.0       1150.37849  1043.76470   \n",
       "11534   201803       20001             591.0       1902.79056  1856.83534   \n",
       "12387   201804       20001             384.0       1286.12277  1251.28462   \n",
       "13241   201805       20001             456.0       1303.62129  1293.89788   \n",
       "14105   201806       20001             497.0       1198.50145  1150.79169   \n",
       "14956   201807       20001             458.0       1528.59380  1470.41009   \n",
       "15802   201808       20001             535.0       1859.88471  1800.96168   \n",
       "16650   201809       20001             401.0       1629.37910  1438.67455   \n",
       "17525   201810       20001             417.0       2423.70881  2295.19832   \n",
       "18422   201811       20001             447.0       1945.84961  1813.01511   \n",
       "19320   201812       20001             453.0       1562.28968  1486.68669   \n",
       "20212   201901       20001             370.0       1371.76430  1275.77351   \n",
       "21099   201902       20001             367.0       1343.99435  1259.09363   \n",
       "\n",
       "      product_category         cat2  sku_size  plan_precios_cuidados  cluster  \\\n",
       "0                   HC  ROPA LAVADO    3000.0                      0        0   \n",
       "785                 HC  ROPA LAVADO    3000.0                      0        0   \n",
       "1566                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "2352                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "3136                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "3942                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "4765                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "5591                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "6438                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "7267                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "8116                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "8976                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "9832                HC  ROPA LAVADO    3000.0                      0        0   \n",
       "10686               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "11534               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "12387               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "13241               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "14105               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "14956               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "15802               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "16650               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "17525               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "18422               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "19320               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "20212               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "21099               HC  ROPA LAVADO    3000.0                      0        0   \n",
       "\n",
       "           target  \n",
       "0      1303.35771  \n",
       "785    1069.96130  \n",
       "1566   1502.20132  \n",
       "2352   1520.06539  \n",
       "3136   1030.67391  \n",
       "3942   1267.39462  \n",
       "4765   1316.94604  \n",
       "5591   1439.75563  \n",
       "6438   1580.47401  \n",
       "7267   1049.38860  \n",
       "8116   1169.07532  \n",
       "8976   1043.76470  \n",
       "9832   1856.83534  \n",
       "10686  1251.28462  \n",
       "11534  1293.89788  \n",
       "12387  1150.79169  \n",
       "13241  1470.41009  \n",
       "14105  1800.96168  \n",
       "14956  1438.67455  \n",
       "15802  2295.19832  \n",
       "16650  1813.01511  \n",
       "17525  1486.68669  \n",
       "18422  1275.77351  \n",
       "19320  1259.09363  \n",
       "20212  1470.65653  \n",
       "21099  1647.63848  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"product_id\"] == 20001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1296"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"product_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "periodo\n",
       "201701    1296\n",
       "201702    1296\n",
       "201901    1296\n",
       "201812    1296\n",
       "201811    1296\n",
       "201810    1296\n",
       "201809    1296\n",
       "201808    1296\n",
       "201807    1296\n",
       "201806    1296\n",
       "201805    1296\n",
       "201804    1296\n",
       "201803    1296\n",
       "201802    1296\n",
       "201801    1296\n",
       "201712    1296\n",
       "201711    1296\n",
       "201710    1296\n",
       "201709    1296\n",
       "201708    1296\n",
       "201707    1296\n",
       "201706    1296\n",
       "201705    1296\n",
       "201704    1296\n",
       "201703    1296\n",
       "201902    1296\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"periodo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by `periodo` just to be sure\n",
    "product_data = df.sort_values([\"product_id\", \"periodo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33696, 11),\n",
       " Index(['periodo', 'product_id', 'cust_request_qty', 'cust_request_tn', 'tn',\n",
       "        'product_category', 'cat2', 'sku_size', 'plan_precios_cuidados',\n",
       "        'cluster', 'target'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_data.shape, product_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using scikit-learn, ONE HOT ENCODE the categorical variables: product_category\n",
    "product_data = pd.get_dummies(product_data, columns=[\"product_category\", \"cat2\"])\n",
    "\n",
    "# sort columns so that 'lag_tn' is the last column in the dataframe\n",
    "product_data = product_data[[col for col in product_data.columns if col != 'target'] + ['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert boolean columns to int\n",
    "product_data = product_data.astype({\"product_category_FOODS\": int, \"product_category_HC\": int, \"product_category_PC\": int, \"product_category_REF\": int, \"product_category_unknown\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "periodo                       int64\n",
       "cat2_VAJILLA                  int64\n",
       "cat2_TE                       int64\n",
       "cat2_SOPAS Y CALDOS           int64\n",
       "cat2_ROPA MANCHAS             int64\n",
       "cat2_ROPA LAVADO              int64\n",
       "cat2_ROPA ACONDICIONADOR      int64\n",
       "cat2_PROFESIONAL              int64\n",
       "cat2_PIEL2                    int64\n",
       "cat2_PIEL1                    int64\n",
       "cat2_OTROS                    int64\n",
       "cat2_HOGAR                    int64\n",
       "cat2_DEOS                     int64\n",
       "cat2_DENTAL                   int64\n",
       "cat2_CABELLO                  int64\n",
       "cat2_ADEREZOS                 int64\n",
       "product_category_unknown      int64\n",
       "product_category_REF          int64\n",
       "product_category_PC           int64\n",
       "product_category_HC           int64\n",
       "product_category_FOODS        int64\n",
       "cluster                       int64\n",
       "plan_precios_cuidados         int64\n",
       "product_id                    int64\n",
       "cat2_unknown                  int64\n",
       "sku_size                    float64\n",
       "tn                          float64\n",
       "cust_request_tn             float64\n",
       "cust_request_qty            float64\n",
       "target                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert bool columns to int\n",
    "values = [\n",
    "    \"CABELLO\",\n",
    "    \"DEOS\",\n",
    "    \"SOPAS Y CALDOS\",\n",
    "    \"ROPA LAVADO\",\n",
    "    \"PIEL2\",\n",
    "    \"PIEL1\",\n",
    "    \"HOGAR\",\n",
    "    \"ADEREZOS\",\n",
    "    \"VAJILLA\",\n",
    "    \"ROPA ACONDICIONADOR\",\n",
    "    \"OTROS\",\n",
    "    \"DENTAL\",\n",
    "    \"PROFESIONAL\",\n",
    "    \"TE\",\n",
    "    \"ROPA MANCHAS\",\n",
    "    \"unknown\"\n",
    "]\n",
    "\n",
    "for value in values:\n",
    "    product_data = product_data.astype({f\"cat2_{value}\": int})\n",
    "product_data.dtypes.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_data.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['periodo', 'product_id', 'cust_request_qty', 'cust_request_tn', 'tn',\n",
       "       'sku_size', 'plan_precios_cuidados', 'cluster',\n",
       "       'product_category_FOODS', 'product_category_HC', 'product_category_PC',\n",
       "       'product_category_REF', 'product_category_unknown', 'cat2_ADEREZOS',\n",
       "       'cat2_CABELLO', 'cat2_DENTAL', 'cat2_DEOS', 'cat2_HOGAR', 'cat2_OTROS',\n",
       "       'cat2_PIEL1', 'cat2_PIEL2', 'cat2_PROFESIONAL',\n",
       "       'cat2_ROPA ACONDICIONADOR', 'cat2_ROPA LAVADO', 'cat2_ROPA MANCHAS',\n",
       "       'cat2_SOPAS Y CALDOS', 'cat2_TE', 'cat2_VAJILLA', 'cat2_unknown',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "train_df = product_data[product_data[\"periodo\"] <= 201811]\n",
    "test_df = product_data[product_data[\"periodo\"] <= 201812]\n",
    "predict_df = product_data[product_data[\"periodo\"] <= 201902]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117197/917755758.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[train_df.columns] = scaler_train.fit_transform(train_df[train_df.columns])\n",
      "/tmp/ipykernel_117197/917755758.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[test_df.columns] = scaler_test.fit_transform(test_df[test_df.columns])\n"
     ]
    }
   ],
   "source": [
    "# standarize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_train = StandardScaler()\n",
    "scaler_test = StandardScaler()\n",
    "scaler_predict_product_id = StandardScaler()\n",
    "scaler_predict_target = StandardScaler()\n",
    "scaler_predict_rest = StandardScaler()\n",
    "\n",
    "rest = [col for col in predict_df.columns if col not in [\"product_id\", \"target\"]]\n",
    "\n",
    "train_df[train_df.columns] = scaler_train.fit_transform(train_df[train_df.columns])\n",
    "test_df[test_df.columns] = scaler_test.fit_transform(test_df[test_df.columns])\n",
    "predict_df[rest] = scaler_predict_rest.fit_transform(predict_df[rest])\n",
    "predict_df[\"target\"] = scaler_predict_target.fit_transform(predict_df[[\"target\"]])\n",
    "predict_df[\"product_id\"] = scaler_predict_product_id.fit_transform(predict_df[[\"product_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_layers, n_neurons, n_steps, X_train, y_train, X_test, y_test):\n",
    "    # Train a single model where product_id is part of the input\n",
    "    print(f\"Training model with {n_layers} layers, {n_neurons} neurons, {n_steps} steps.\")\n",
    "\n",
    "    # Number of features (should be 6: 'product_id' to 'lag_plan_precios_cuidados')\n",
    "    n_features = X_train.shape[2]\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation=\"relu\", input_shape=(n_steps, n_features)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    # Define EarlyStopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(n_steps, model, X_predict, y_predict):\n",
    "    rows = []\n",
    "    # for each product_id, generate a prediction for 201904\n",
    "    for i, product in enumerate(predict_df[\"product_id\"].unique()):\n",
    "        print(\n",
    "            f\"Predicting 201904 for product {product} ({i+1}/{len(predict_df['product_id'].unique())}))\"\n",
    "        )\n",
    "\n",
    "        this_predict_df = predict_df[predict_df[\"product_id\"] == product]\n",
    "\n",
    "        this_predict_df_array = this_predict_df.values\n",
    "\n",
    "        n_features = X_predict.shape[2]\n",
    "\n",
    "        # Prepare the input for prediction\n",
    "        x_input = this_predict_df_array[-n_steps:, :-1]\n",
    "        x_input = x_input.reshape((1, n_steps, n_features))\n",
    "\n",
    "        # Make prediction\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        if yhat[0][0] < 1:\n",
    "            yhat[0][0] = 0\n",
    "\n",
    "        # Append to final output DataFrame\n",
    "        rows.append(\n",
    "            {\n",
    "                \"product_id\": product,\n",
    "                \"target\": yhat[0][0],\n",
    "            }\n",
    "        )\n",
    "        final_output = pd.DataFrame(\n",
    "            rows,\n",
    "            columns=[\"product_id\", \"target\"],\n",
    "        )\n",
    "        final_output = final_output.sort_values(\"product_id\", ascending=True)\n",
    "        timestamp = datetime.now().timestamp()\n",
    "        final_output.to_csv(f\"./output/output_lstm8_cluster_por_producto_{timestamp}.csv\", index=False)\n",
    "        print(\"//////////////////////////////////////\")\n",
    "        print(X_predict.shape, y_predict.shape, final_output.shape)\n",
    "        print(\"//////////////////////////////////////\")\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(predictions):\n",
    "    # revert the standarization for the output\n",
    "    predictions[\"target\"] = scaler_predict_target.inverse_transform(predictions[[\"target\"]])\n",
    "    predictions[\"product_id\"] = scaler_predict_product_id.inverse_transform(predictions[[\"product_id\"]])\n",
    "    \n",
    "    predictions[\"product_id\"] = predictions[\"product_id\"].astype(int)\n",
    "    predictions.rename(columns={\"target\": \"prediction\"}, inplace=True)\n",
    "    \n",
    "    return calculate_error_2(predictions, 201904)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 1 layers, [25, 25, 25, 25] neurons, 1 steps.\n",
      "WARNING:tensorflow:Layer lstm_101 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "932/932 [==============================] - 5s 4ms/step - loss: 0.1866 - val_loss: 0.1302\n",
      "Epoch 2/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1320 - val_loss: 0.1311\n",
      "Epoch 3/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1326 - val_loss: 0.1288\n",
      "Epoch 4/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1281 - val_loss: 0.1188\n",
      "Epoch 5/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1242 - val_loss: 0.1191\n",
      "Epoch 6/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1248 - val_loss: 0.1150\n",
      "Epoch 7/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1221 - val_loss: 0.1180\n",
      "Epoch 8/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1242 - val_loss: 0.1133\n",
      "Epoch 9/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1239 - val_loss: 0.1144\n",
      "Epoch 10/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1213 - val_loss: 0.1156\n",
      "Epoch 11/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1210 - val_loss: 0.1309\n",
      "Epoch 12/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1193 - val_loss: 0.1158\n",
      "Epoch 13/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1192 - val_loss: 0.1110\n",
      "Epoch 14/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1183 - val_loss: 0.1114\n",
      "Epoch 15/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1201 - val_loss: 0.1107\n",
      "Epoch 16/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1178 - val_loss: 0.1098\n",
      "Epoch 17/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1175 - val_loss: 0.1114\n",
      "Epoch 18/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1176 - val_loss: 0.1099\n",
      "Epoch 19/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1149 - val_loss: 0.1296\n",
      "Epoch 20/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1162 - val_loss: 0.1105\n",
      "Epoch 21/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1134 - val_loss: 0.1247\n",
      "Epoch 22/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1154 - val_loss: 0.1091\n",
      "Epoch 23/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1151 - val_loss: 0.1063\n",
      "Epoch 24/200\n",
      "932/932 [==============================] - 3s 3ms/step - loss: 0.1144 - val_loss: 0.1075\n",
      "Epoch 25/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1133 - val_loss: 0.1119\n",
      "Epoch 26/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1144 - val_loss: 0.1098\n",
      "Epoch 27/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1132 - val_loss: 0.1072\n",
      "Epoch 28/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1119 - val_loss: 0.1059\n",
      "Epoch 29/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1141 - val_loss: 0.1077\n",
      "Epoch 30/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1120 - val_loss: 0.1054\n",
      "Epoch 31/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1101 - val_loss: 0.1141\n",
      "Epoch 32/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1101 - val_loss: 0.1101\n",
      "Epoch 33/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1104 - val_loss: 0.1096\n",
      "Epoch 34/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1133 - val_loss: 0.1034\n",
      "Epoch 35/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1115 - val_loss: 0.1046\n",
      "Epoch 36/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1114 - val_loss: 0.1056\n",
      "Epoch 37/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1099 - val_loss: 0.1059\n",
      "Epoch 38/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1095 - val_loss: 0.1051\n",
      "Epoch 39/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1097 - val_loss: 0.1029\n",
      "Epoch 40/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1111 - val_loss: 0.1031\n",
      "Epoch 41/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1093 - val_loss: 0.1019\n",
      "Epoch 42/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1070 - val_loss: 0.1059\n",
      "Epoch 43/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1076 - val_loss: 0.1025\n",
      "Epoch 44/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1089 - val_loss: 0.1063\n",
      "Epoch 45/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1083 - val_loss: 0.1028\n",
      "Epoch 46/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1083 - val_loss: 0.1011\n",
      "Epoch 47/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1062 - val_loss: 0.1054\n",
      "Epoch 48/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1082 - val_loss: 0.1027\n",
      "Epoch 49/200\n",
      "932/932 [==============================] - 3s 3ms/step - loss: 0.1049 - val_loss: 0.1290\n",
      "Epoch 50/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1097 - val_loss: 0.1012\n",
      "Epoch 51/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1056 - val_loss: 0.1120\n",
      "Epoch 52/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1059 - val_loss: 0.1017\n",
      "Epoch 53/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1074 - val_loss: 0.1054\n",
      "Epoch 54/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1045 - val_loss: 0.1057\n",
      "Epoch 55/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1063 - val_loss: 0.1000\n",
      "Epoch 56/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1056 - val_loss: 0.1047\n",
      "Epoch 57/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1054 - val_loss: 0.0982\n",
      "Epoch 58/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1050 - val_loss: 0.0978\n",
      "Epoch 59/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1052 - val_loss: 0.0983\n",
      "Epoch 60/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1052 - val_loss: 0.0985\n",
      "Epoch 61/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1058 - val_loss: 0.0998\n",
      "Epoch 62/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1057 - val_loss: 0.1012\n",
      "Epoch 63/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1039 - val_loss: 0.0997\n",
      "Epoch 64/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1043 - val_loss: 0.0983\n",
      "Epoch 65/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1036 - val_loss: 0.0978\n",
      "Epoch 66/200\n",
      "932/932 [==============================] - 3s 4ms/step - loss: 0.1007 - val_loss: 0.1085\n",
      "Epoch 67/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1044 - val_loss: 0.0994\n",
      "Epoch 68/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1020 - val_loss: 0.1010\n",
      "Predicting 201904 for product -1.7295502593206864 (1/1296))\n",
      "//////////////////////////////////////\n",
      "(33696, 1, 29) (33696,) (1, 2)\n",
      "//////////////////////////////////////\n",
      "Training model with 1 layers, [25, 25, 25, 25] neurons, 2 steps.\n",
      "WARNING:tensorflow:Layer lstm_102 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/200\n",
      "932/932 [==============================] - 5s 5ms/step - loss: 0.1622 - val_loss: 0.1148\n",
      "Epoch 2/200\n",
      "932/932 [==============================] - 4s 5ms/step - loss: 0.1266 - val_loss: 0.1134\n",
      "Epoch 3/200\n",
      "932/932 [==============================] - 4s 4ms/step - loss: 0.1175 - val_loss: 0.1319\n",
      "Epoch 4/200\n",
      "932/932 [==============================] - 4s 5ms/step - loss: 0.1240 - val_loss: 0.1083\n",
      "Epoch 5/200\n",
      "932/932 [==============================] - 4s 5ms/step - loss: 0.1153 - val_loss: 0.1075\n",
      "Epoch 6/200\n",
      "932/932 [==============================] - 4s 5ms/step - loss: 0.1135 - val_loss: 0.1082\n",
      "Epoch 7/200\n",
      "920/932 [============================>.] - ETA: 0s - loss: 0.1089"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gero/Documents/Austral/Laboratorio de Implementación 3/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gero/Documents/Austral/Laboratorio%20de%20Implementaci%C3%B3n%203/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m X_test, y_test \u001b[39m=\u001b[39m split_sequences(test_df\u001b[39m.\u001b[39mvalues, n_steps)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/gero/Documents/Austral/Laboratorio%20de%20Implementaci%C3%B3n%203/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X_predict, y_predict \u001b[39m=\u001b[39m split_sequences(predict_df\u001b[39m.\u001b[39mvalues, n_steps)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gero/Documents/Austral/Laboratorio%20de%20Implementaci%C3%B3n%203/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model \u001b[39m=\u001b[39m train_model(n_layers, n_neurons, n_steps, X_train, y_train, X_test, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gero/Documents/Austral/Laboratorio%20de%20Implementaci%C3%B3n%203/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m predictions \u001b[39m=\u001b[39m make_predictions(n_steps, model, X_predict, y_predict)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gero/Documents/Austral/Laboratorio%20de%20Implementaci%C3%B3n%203/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m score \u001b[39m=\u001b[39m calculate_score(predictions)\n",
      "\u001b[1;32m/home/gero/Documents/Austral/Laboratorio de Implementación 3/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gero/Documents/Austral/Laboratorio%20de%20Implementaci%C3%B3n%203/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb#X36sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gero/Documents/Austral/Laboratorio%20de%20Implementaci%C3%B3n%203/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb#X36sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/gero/Documents/Austral/Laboratorio%20de%20Implementaci%C3%B3n%203/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb#X36sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), callbacks\u001b[39m=\u001b[39;49m[early_stopping], verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/gero/Documents/Austral/Laboratorio%20de%20Implementaci%C3%B3n%203/consultoria-multinacional/LSTM/lstm8_cluster_productos.ipynb#X36sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:1791\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1776\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1777\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1778\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1789\u001b[0m         pss_evaluation_shards\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1790\u001b[0m     )\n\u001b[0;32m-> 1791\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1792\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1793\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1794\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1795\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1796\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1797\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1798\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1799\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1800\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1801\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1802\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1803\u001b[0m )\n\u001b[1;32m   1804\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1805\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1806\u001b[0m }\n\u001b[1;32m   1807\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:2200\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2196\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2197\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2198\u001b[0m             ):\n\u001b[1;32m   2199\u001b[0m                 callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2200\u001b[0m                 logs \u001b[39m=\u001b[39m test_function_runner\u001b[39m.\u001b[39;49mrun_step(\n\u001b[1;32m   2201\u001b[0m                     dataset_or_iterator,\n\u001b[1;32m   2202\u001b[0m                     data_handler,\n\u001b[1;32m   2203\u001b[0m                     step,\n\u001b[1;32m   2204\u001b[0m                     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pss_evaluation_shards,\n\u001b[1;32m   2205\u001b[0m                 )\n\u001b[1;32m   2207\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2208\u001b[0m \u001b[39m# Override with model metrics instead of last step logs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:4000\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   3999\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(\u001b[39mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4000\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function(dataset_or_iterator)\n\u001b[1;32m   4001\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   4002\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:835\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    834\u001b[0m   \u001b[39mif\u001b[39;00m without_tracing:\n\u001b[0;32m--> 835\u001b[0m     _frequent_tracing_detector_manager\u001b[39m.\u001b[39;49mcalled_without_tracing(\n\u001b[1;32m    836\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_key_for_call_stats)\n\u001b[1;32m    837\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    838\u001b[0m     _frequent_tracing_detector_manager\u001b[39m.\u001b[39mcalled_with_tracing(\n\u001b[1;32m    839\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key_for_call_stats, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_python_function,\n\u001b[1;32m    840\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_omit_frequent_tracing_warning)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:196\u001b[0m, in \u001b[0;36m_FrequentTracingDetectorManager.called_without_tracing\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detectors[key] \u001b[39m=\u001b[39m _FrequentTracingDetector()\n\u001b[1;32m    194\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detectors[key]\n\u001b[0;32m--> 196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalled_without_tracing\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m    197\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    198\u001b[0m     detector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_detector(key)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g_s_rows = []\n",
    "for n_layers in NUMBER_OF_LAYERS:\n",
    "    for n_neurons in NUMBER_OF_NEURONS:\n",
    "        for n_steps in NUMBER_OF_STEPS:\n",
    "\n",
    "            X_train, y_train = split_sequences(train_df.values, n_steps)\n",
    "            X_test, y_test = split_sequences(test_df.values, n_steps)\n",
    "            X_predict, y_predict = split_sequences(predict_df.values, n_steps)\n",
    "\n",
    "            model = train_model(n_layers, n_neurons, n_steps, X_train, y_train, X_test, y_test)\n",
    "            predictions = make_predictions(n_steps, model, X_predict, y_predict)\n",
    "            score = calculate_score(predictions)\n",
    "\n",
    "            g_s_rows.append(\n",
    "                {\n",
    "                    \"n_layers\": n_layers,\n",
    "                    \"n_neurons\": n_neurons,\n",
    "                    \"n_steps\": n_steps,\n",
    "                    \"score\": score,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            g_s_df = pd.DataFrame(g_s_rows)\n",
    "            g_s_df.to_csv(f\"./output/grid_search_lstm8_cluster_productos_{n_layers}_{n_neurons[0]}_{n_steps}_{score}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
